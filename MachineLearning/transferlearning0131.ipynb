{"cells":[{"cell_type":"raw","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-31T13:14:37.387103Z","iopub.status.busy":"2024-01-31T13:14:37.386452Z"}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-31T14:31:37.572382Z","iopub.status.busy":"2024-01-31T14:31:37.571781Z","iopub.status.idle":"2024-01-31T14:31:52.423985Z","shell.execute_reply":"2024-01-31T14:31:52.422880Z","shell.execute_reply.started":"2024-01-31T14:31:37.572349Z"},"trusted":true},"outputs":[],"source":["!pip install tflite-runtime"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-31T14:04:13.098060Z","iopub.status.busy":"2024-01-31T14:04:13.097688Z","iopub.status.idle":"2024-01-31T14:07:57.601259Z","shell.execute_reply":"2024-01-31T14:07:57.600271Z","shell.execute_reply.started":"2024-01-31T14:04:13.098027Z"},"trusted":true},"outputs":[],"source":["###############################\n","# cats vs dog\n","# EFFICIENT NET\n","# https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\n","################################\n","# (순서)전이학습 모델 선정 -> 데이터셋 크기 설정\n","import numpy as np\n","import matplotlib.pylab as plt\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","import tflite_runtime.interpreter as tflite\n","\n","\n","###########전이학습을 위한 이미지 특성 벡터 생성하는 모델 선택하기########## \n","handle_base_name = \"effNet_v2_1k_b0_fv_v2\" # @param ['mobilenet_v2_tf2_pre_fv_v4', 'mobilenet_v2_140_224_v2', 'effNet_v2_1k_b0_fv_v2']\n","\n","#링크 \n","handle_base_map = {\n","  \"mobilenet_v2_tf2_pre_fv_v4\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\",\n","  \"mobilenet_v2_140_224_v2\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/140-224-feature-vector/versions/2\",\n","  \"effNet_v2_1k_b0_fv_v2\": \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\",\n","}\n","\n","#인풋 이미지 사이즈 크기 \n","handle_base_image_size_map = {\n","  \"mobilenet_v2_tf2_pre_fv_v4\": 224,\n","  \"mobilenet_v2_140_224_v2\": 224,\n","  \"effNet_v2_1k_b0_fv_v2\": 224,\n","}\n","\n","#아웃풋 FEATURE VECTOR SIZE \n","handle_base_output_map ={\n","  \"mobilenet_v2_tf2_pre_fv_v4\":1280,\n","  \"mobilenet_v2_140_224_v2\": 1792,\n","  \"effNet_v2_1k_b0_fv_v2\": 1280  \n","    \n","}\n","\n","model_handle = handle_base_map.get(handle_base_name)\n","pixels = handle_base_image_size_map.get(handle_base_name, 224) #(2번째 파라미터는 해당 모델이 없을 시, 디폴트값\n","feature_vector_size = handle_base_output_map.get(handle_base_name)\n","IMAGE_SIZE = (pixels, pixels)\n","\n","print(f\"Selected model: {handle_base_name} : {model_handle}\")\n","print(f\"Input size {IMAGE_SIZE}, Output feature vector size {feature_vector_size}\")\n","\n","feature_extractor = hub.KerasLayer(\n","    model_handle,\n","    input_shape = IMAGE_SIZE +(3,),\n","    output_shape = [feature_vector_size],\n","    trainable = False\n",")\n","BATCH_SIZE = 32\n","\n","\n","##########데이터세트 설정하기 (모델에 맞게 이미지 조정)##########\n","#244x 244 사이즈로 리사이즈를 하고, 정규화를 해줍니다.\n","def format_image(image,label):\n","    image = tf.image.resize(image,(224,224))/255.0\n","    return image, label\n","\n","#훈련, 검증, 테스트 세트로 나눕니다.\n","(raw_train, raw_validation, raw_test), metadata =tfds.load(\n","    'cats_vs_dogs',\n","    split=['train[:80%]','train[80%:90%]','train[90%:]'],\n","    with_info=True,\n","    as_supervised=True,\n",")\n","\n","print(metadata)\n","\n","num_examples = metadata.splits['train'].num_examples\n","num_classes = metadata.features['label'].num_classes\n","class_names = metadata.features['label'].names\n","\n","train_batches = raw_train.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n","validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n","test_batches = raw_test.map(format_image).batch(1)\n","\n","\n","##########모델 정의하기#############\n","model = tf.keras.Sequential([\n","    feature_extractor,#우리가 선택한 전이학습 모델\n","    tf.keras.layers.Dense(num_classes, activation ='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss ='sparse_categorical_crossentropy',\n","    metrics =['accuracy']\n",")\n","\n","hist = model.fit(\n","    train_batches,\n","    epochs = 5,\n","    validation_data = validation_batches\n",").history\n","\n","model.summary()\n","\n","#트레이닝 결과 그래프 보여주기 \n","plt.figure()\n","plt.ylabel(\"Loss (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,2])\n","plt.plot(hist[\"loss\"],label='loss')\n","plt.plot(hist[\"val_loss\"],label='val_loss')\n","plt.legend(loc='upper right')\n","\n","plt.figure()\n","plt.ylabel(\"Accuracy (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,1])\n","plt.plot(hist[\"accuracy\"],label='accu')\n","plt.plot(hist[\"val_accuracy\"],label='val_acc')\n","plt.legend(loc='lower right')\n","\n","#학습된 모델 저장하기\n","_SAVED_MODEL = \"/content/drive/MyDrive/INTEL_PYTHON/effNET_exp_saved_model\"\n","tf.saved_model.save(model, _SAVED_MODEL)\n","\n","#tensoflow lite로 변환하기\n","converter = tf.lite.TFLiteConverter.from_saved_model(_SAVED_MODEL)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_model = converter.convert()\n","tflite_model_file = '/content/drive/MyDrive/INTEL_PYTHON/effNET_converted_model.tflite'\n","\n","#with open(…) as f 에서 f는 open(…)함수가 리턴한 file object.\n","with open(tflite_model_file, \"wb\") as f:\n","  f.write(tflite_model)\n","\n","###########################\n","## 라즈베리 파이에서 실행할 추론 코드 \n","###########################\n","\n","#모델 로드\n","interpreter = tflite.Interpreter(model_path='/content/drive/MyDrive/INTEL_PYTHON/effNET_converted_model.tflite')\n","\n","#텐서 할당\n","interpreter.allocate_tensors()\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","input_details = interpreter.get_input_details()[0]\n","print('input: ', input_details)\n","output_details = interpreter.get_output_details()[0]\n","print('output: ', output_details)\n","\n","predictions =[]\n","\n","#테스트 데이터로 추론하기 \n","predictions =[]\n","test_labels, test_imgs = [],[]\n","for img, label in test_batches.take(100):\n","    interpreter.set_tensor(input_index, img)\n","    interpreter.invoke()\n","    predictions.append(interpreter.get_tensor(output_index))\n","    test_labels.append(label.numpy()[0])\n","    test_imgs.append(img)\n","\n","#추론 결과 확인하기 \n","score  = 0\n","for item in range(0,100):\n","    prediction = np.argmax(predictions[item])\n","    label = test_labels[item]\n","    if prediction == label:\n","        score = score +1\n","\n","print(\"100개 중 맞은 예측 수: \"+ str(score))\n","\n","def plot_image(i, predictions_array, true_label, img):\n","    true_label, img = true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    img = tf.squeeze(img) \n","    plt.imshow(img)\n","\n","    predicted_label = np.argmax(predictions_array[i])\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","\n","    plt.xlabel(\"{} {:2.0f}%\\n ({})\".format(class_names[predicted_label],\n","                                    100*np.max(predictions_array),\n","                                    class_names[true_label]),\n","                                    color=color)\n","\n","\n","for index in range(0,99): \n","    match (index%9):\n","        case (0): \n","            plt.figure(figsize=(9,9)) \n","            plt.subplot(331)\n","        case (1):\n","            plt.subplot(332)\n","        case (2):\n","            plt.subplot(333)\n","        case (3):\n","            plt.subplot(334)\n","        case (4):\n","            plt.subplot(335)\n","        case (5):\n","            plt.subplot(336)\n","        case (6):\n","            plt.subplot(337)\n","        case (7):\n","            plt.subplot(338)\n","        case (8):\n","            plt.subplot(339)\n","            plot_image(index, predictions, test_labels, test_imgs)\n","            plt.suptitle('Figure{}'.format(int(index/8)))\n","            #plt.savefig('resultImg/result{}.png'.format(int(i/8)))\n","            continue             \n","    plot_image(index, predictions, test_labels, test_imgs)\n","# for index in range(0,99):\n","#     if index%2 == 0 :\n","#       plt.figure(figsize = (6,3))\n","#       plt.subplot(121)\n","#     elif index %2 ==1 :\n","#       plt.subplot(122)\n","\n","#     plot_image(index, predictions, test_labels, test_imgs)\n","#       #imgFile = 'resultImg/result{}.png'.format(index)\n","#       #plt.savefig(imgFile)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-31T14:14:33.448197Z","iopub.status.busy":"2024-01-31T14:14:33.447486Z","iopub.status.idle":"2024-01-31T14:22:34.690161Z","shell.execute_reply":"2024-01-31T14:22:34.689266Z","shell.execute_reply.started":"2024-01-31T14:14:33.448157Z"},"trusted":true},"outputs":[],"source":["###############################\n","## eurosat\n","#mobilenet-v2/frameworks/TensorFlow2/variations/140-224-feature-vector/versions/2\n","################################\n","\n","import numpy as np\n","import matplotlib.pylab as plt\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","import tflite_runtime.interpreter as tflite\n","\n","\n","###########전이학습을 위한 이미지 특성 벡터 생성하는 모델 선택하기########## \n","handle_base_name = \"mobilenet_v2_140_224_v2\" # @param ['mobilenet_v2_tf2_pre_fv_v4', 'mobilenet_v2_140_224_v2', 'effNet_v2_1k_b0_fv_v2']\n","\n","#링크 \n","handle_base_map = {\n","  \"mobilenet_v2_tf2_pre_fv_v4\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\",\n","  \"mobilenet_v2_140_224_v2\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/140-224-feature-vector/versions/2\",\n","  \"effNet_v2_1k_b0_fv_v2\": \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\",\n","}\n","\n","#인풋 이미지 사이즈 크기 \n","handle_base_image_size_map = {\n","  \"mobilenet_v2_tf2_pre_fv_v4\": 224,\n","  \"mobilenet_v2_140_224_v2\": 224,\n","  \"effNet_v2_1k_b0_fv_v2\": 224,\n","}\n","\n","#아웃풋 FEATURE VECTOR SIZE \n","handle_base_output_map ={\n","  \"mobilenet_v2_tf2_pre_fv_v4\":1280,\n","  \"mobilenet_v2_140_224_v2\": 1792,\n","  \"effNet_v2_1k_b0_fv_v2\": 1280  \n","    \n","}\n","\n","model_handle = handle_base_map.get(handle_base_name)\n","pixels = handle_base_image_size_map.get(handle_base_name, 224) #(2번째 파라미터는 해당 모델이 없을 시, 디폴트값\n","feature_vector_size = handle_base_output_map.get(handle_base_name)\n","IMAGE_SIZE = (pixels, pixels)\n","\n","print(f\"Selected model: {handle_base_name} : {model_handle}\")\n","print(f\"Input size {IMAGE_SIZE}, Output feature vector size {feature_vector_size}\")\n","\n","feature_extractor = hub.KerasLayer(\n","    model_handle,\n","    input_shape = IMAGE_SIZE +(3,),\n","    output_shape = [feature_vector_size],\n","    trainable = False\n",")\n","BATCH_SIZE = 30\n","\n","##########데이터세트 설정하기 (모델에 맞게 이미지 조정)##########\n","#244x 244 사이즈로 리사이즈를 하고, 정규화를 해줍니다.\n","def format_image(image,label):\n","    image = tf.image.resize(image,(224,224))/255.0\n","    return image, label\n","\n","#훈련, 검증, 테스트 세트로 나눕니다.\n","(raw_train, raw_validation, raw_test), metadata =tfds.load(\n","    'eurosat',\n","    split=['train[:80%]','train[80%:90%]','train[90%:]'],\n","    with_info=True,\n","    as_supervised=True,\n",")\n","\n","print(metadata)\n","\n","num_examples = metadata.splits['train'].num_examples\n","num_classes = metadata.features['label'].num_classes\n","class_names =metadata.features['label'].names\n","print(class_names)\n","\n","fig = tfds.show_examples(raw_train, metadata)\n","\n","train_batches = raw_train.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n","validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n","test_batches = raw_test.map(format_image).batch(1)\n","\n","##########모델 정의하기#############\n","\n","model = tf.keras.Sequential([\n","    feature_extractor,\n","    tf.keras.layers.Dense(num_classes, activation ='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam', #sgd 사용하지 말것\n","    loss ='sparse_categorical_crossentropy',\n","    metrics =['accuracy']\n",")\n","\n","hist = model.fit(\n","    train_batches,\n","    epochs = 10,\n","    validation_data = validation_batches\n",").history\n","\n","model.summary()\n","\n","#트레이닝 결과 그래프 보여주기 \n","plt.figure()\n","plt.ylabel(\"Loss (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,2])\n","plt.plot(hist[\"loss\"],label='loss')\n","plt.plot(hist[\"val_loss\"],label='val_loss')\n","plt.legend(loc='upper right')\n","\n","\n","plt.figure()\n","plt.ylabel(\"Accuracy (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,1])\n","plt.plot(hist[\"accuracy\"],label='accu')\n","plt.plot(hist[\"val_accuracy\"],label='val_acc')\n","plt.legend(loc='lower right')\n","\n","#학습된 모델 저장하기\n","_SAVED_MODEL = \"/content/drive/MyDrive/INTEL_PYTHON/eurosat140_224_saved_model\"\n","tf.saved_model.save(model, _SAVED_MODEL)\n","\n","#tensoflow lite로 변환하기\n","converter = tf.lite.TFLiteConverter.from_saved_model(_SAVED_MODEL)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT] #최적화 \n","tflite_model = converter.convert()\n","tflite_model_file = '/content/drive/MyDrive/INTEL_PYTHON/eurosat140_224_converted_model.tflite'\n","\n","#with open(…) as f 에서 f는 open(…)함수가 리턴한 file object.\n","with open(tflite_model_file, \"wb\") as f:\n","  f.write(tflite_model)\n","\n","\n","###########################\n","## 라즈베리 파이에서 실행할 추론 코드 \n","###########################\n","\n","interpreter = tflite.Interpreter(model_path='/content/drive/MyDrive/INTEL_PYTHON/eurosat140_224_converted_model.tflite')\n","\n","#텐서 할당\n","interpreter.allocate_tensors()\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","#input, output 텐서 정보 확인 \n","input_details = interpreter.get_input_details()[0]\n","print('input: ', input_details)\n","output_details = interpreter.get_output_details()[0]\n","print('output: ', output_details)\n","\n","predictions =[]\n","\n","# print(input_index)\n","# print(output_index)\n","\n","#테스트 데이터로 추론하기 \n","predictions =[]\n","test_labels, test_imgs = [],[]\n","for img, label in test_batches.take(100):\n","    interpreter.set_tensor(input_index, img)\n","    interpreter.invoke()\n","    predictions.append(interpreter.get_tensor(output_index))\n","    test_labels.append(label.numpy()[0])\n","    test_imgs.append(img)\n","\n","\n","#추론 결과 확인하기 \n","score  = 0\n","for item in range(0,100):\n","    prediction = np.argmax(predictions[item])\n","    label = test_labels[item]\n","    if prediction == label:\n","        score = score +1\n","\n","print(\"100개 중 맞은 예측 수: \"+ str(score))\n","\n","def plot_image(index, predictions_array, true_label, img):\n","    true_label, img = true_label[index], img[index]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    img = tf.squeeze(img)\n","    plt.imshow(img)\n","\n","    predicted_label = np.argmax(predictions_array[index])\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","\n","    plt.xlabel(\"{} {:2.0f}%\\n ({})\".format(class_names[predicted_label],\n","                                    100*np.max(predictions_array),\n","                                    class_names[true_label]),\n","                                    color=color)\n","\n","\n","for index in range(0,99): \n","    match (index%9):\n","        case (0): \n","            plt.figure(figsize=(9,9)) \n","            plt.subplot(331)\n","        case (1):\n","            plt.subplot(332)\n","        case (2):\n","            plt.subplot(333)\n","        case (3):\n","            plt.subplot(334)\n","        case (4):\n","            plt.subplot(335)\n","        case (5):\n","            plt.subplot(336)\n","        case (6):\n","            plt.subplot(337)\n","        case (7):\n","            plt.subplot(338)\n","        case (8):\n","            plt.subplot(339)\n","            plot_image(index, predictions, test_labels, test_imgs)\n","            plt.suptitle('Figure{}'.format(int(index/8)))\n","            #plt.savefig('resultImg/result{}.png'.format(int(i/8)))\n","            continue             \n","    plot_image(index, predictions, test_labels, test_imgs)\n","    \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-31T14:31:58.408708Z","iopub.status.busy":"2024-01-31T14:31:58.408361Z","iopub.status.idle":"2024-01-31T14:36:04.594276Z","shell.execute_reply":"2024-01-31T14:36:04.593271Z","shell.execute_reply.started":"2024-01-31T14:31:58.408678Z"},"trusted":true},"outputs":[],"source":["###############################\n","## 말라리아 malaria\n","#['parasitized', 'uninfected']\n","#mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\n","################################\n","\n","import numpy as np\n","import matplotlib.pylab as plt\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","import tflite_runtime.interpreter as tflite\n","\n","###########전이학습을 위한 이미지 특성 벡터 생성하는 모델 선택하기########## \n","handle_base_name = \"mobilenet_v2_tf2_pre_fv_v4\" # @param ['mobilenet_v2_tf2_pre_fv_v4', 'mobilenet_v2_140_224_v2', 'effNet_v2_1k_b0_fv_v2']\n","\n","#링크 \n","handle_base_map = {\n","  \"mobilenet_v2_tf2_pre_fv_v4\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-feature-vector/versions/4\",\n","  \"mobilenet_v2_140_224_v2\": \"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/140-224-feature-vector/versions/2\",\n","  \"effNet_v2_1k_b0_fv_v2\": \"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b0-feature-vector/versions/2\",\n","}\n","\n","#인풋 이미지 사이즈 크기 \n","handle_base_image_size_map = {\n","  \"mobilenet_v2_tf2_pre_fv_v4\": 224,\n","  \"mobilenet_v2_140_224_v2\": 224,\n","  \"effNet_v2_1k_b0_fv_v2\": 224,\n","}\n","\n","#아웃풋 FEATURE VECTOR SIZE \n","handle_base_output_map ={\n","  \"mobilenet_v2_tf2_pre_fv_v4\":1280,\n","  \"mobilenet_v2_140_224_v2\": 1792,\n","  \"effNet_v2_1k_b0_fv_v2\": 1280  \n","    \n","}\n","\n","model_handle = handle_base_map.get(handle_base_name)\n","pixels = handle_base_image_size_map.get(handle_base_name, 224) #(2번째 파라미터는 해당 모델이 없을 시, 디폴트값\n","feature_vector_size = handle_base_output_map.get(handle_base_name)\n","IMAGE_SIZE = (pixels, pixels)\n","\n","print(f\"Selected model: {handle_base_name} : {model_handle}\")\n","print(f\"Input size {IMAGE_SIZE}, Output feature vector size {feature_vector_size}\")\n","\n","feature_extractor = hub.KerasLayer(\n","    model_handle,\n","    input_shape = IMAGE_SIZE +(3,),\n","    output_shape = [feature_vector_size],\n","    trainable = False\n",")\n","BATCH_SIZE = 32\n","\n","##########데이터세트 설정하기 (모델에 맞게 이미지 조정)##########\n","\n","#244x 244 사이즈로 리사이즈를 하고, 정규화를 해줍니다.\n","def format_image(image,label):\n","    image = tf.image.resize(image,(224,224))/255.0\n","    return image, label\n","\n","#훈련, 검증, 테스트 세트로 나눕니다.\n","(raw_train, raw_validation, raw_test), metadata =tfds.load(\n","    'malaria',\n","    split=['train[:80%]','train[80%:90%]','train[90%:]'],\n","    with_info=True,\n","    as_supervised=True,\n",")\n","\n","print(metadata)\n","\n","num_examples = metadata.splits['train'].num_examples\n","num_classes = metadata.features['label'].num_classes\n","class_names =metadata.features['label'].names\n","print(class_names)\n","\n","#train data 대표 이미지 9개 보여주기 \n","fig = tfds.show_examples(raw_train, metadata)\n","\n","train_batches = raw_train.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n","validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n","test_batches = raw_test.map(format_image).batch(1)\n","\n","##########모델 정의하기#############\n","\n","model = tf.keras.Sequential([\n","    feature_extractor,\n","    tf.keras.layers.Dense(num_classes, activation ='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss ='sparse_categorical_crossentropy',\n","    metrics =['accuracy']\n",")\n","\n","hist = model.fit(\n","    train_batches,\n","    epochs = 5,\n","    validation_data = validation_batches\n",").history\n","\n","model.summary()\n","\n","#트레이닝 결과 그래프 보여주기 \n","plt.figure()\n","plt.ylabel(\"Loss (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,2])\n","plt.plot(hist[\"loss\"],label='loss')\n","plt.plot(hist[\"val_loss\"],label='val_loss')\n","plt.legend(loc='upper right')\n","\n","plt.figure()\n","plt.ylabel(\"Accuracy (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,1])\n","plt.plot(hist[\"accuracy\"],label='accu')\n","plt.plot(hist[\"val_accuracy\"],label='val_acc')\n","plt.legend(loc='lower right')\n","\n","#학습된 모델 saved_model로 저장하기 \n","#_SAVED_MODEL = \"./content/drive/MyDrive/INTEL_PYTHON/malaria_saved_model\"\n","_SAVED_MODEL = \"malaria_saved_model\"\n","\n","tf.saved_model.save(model, _SAVED_MODEL)\n","\n","# tensoflow Lite 파일 생성하기 \n","converter = tf.lite.TFLiteConverter.from_saved_model(_SAVED_MODEL)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT] #Dynamic Range Quantization\n","tflite_model = converter.convert()\n","tflite_model_file = 'malaria_converted_model.tflite'\n","\n","#with open(…) as f 에서 f는 open(…)함수가 리턴한 file object.\n","with open(tflite_model_file, \"wb\") as f:\n","  f.write(tflite_model)\n","\n","\n","###########################\n","## 라즈베리 파이에서 실행할 추론 코드 \n","###########################\n","\n","#인터프리터 생성 \n","interpreter = tflite.Interpreter(model_path='malaria_converted_model.tflite')\n","\n","#텐서 할당\n","interpreter.allocate_tensors()\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]\n","\n","#input, output 텐서 정보 확인 \n","input_details = interpreter.get_input_details()[0]\n","print('input: ', input_details)\n","output_details = interpreter.get_output_details()[0]\n","print('output: ', output_details)\n","\n","predictions =[]\n","\n","# print(input_index)\n","# print(output_index)\n","\n","#추론하기 \n","predictions =[]\n","test_labels, test_imgs = [],[]\n","for img, label in test_batches.take(100):\n","    interpreter.set_tensor(input_index, img)\n","    interpreter.invoke()\n","    predictions.append(interpreter.get_tensor(output_index))\n","    test_labels.append(label.numpy()[0])\n","    test_imgs.append(img)\n","\n","\n","#추론 결과 점수로 확인하기 \n","score  = 0\n","for item in range(0,100):\n","    prediction = np.argmax(predictions[item])\n","    label = test_labels[item]\n","    if prediction == label:\n","        score = score +1\n","\n","print(\"100개 중 맞은 예측 수: \"+ str(score))\n","\n","def plot_image(i, predictions_array, true_label, img):\n","    true_label, img = true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    img = tf.squeeze(img) \n","    plt.imshow(img)\n","\n","    predicted_label = np.argmax(predictions_array[index])\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","\n","    plt.xlabel(f\"{class_names[predicted_label]} {100*np.max(predictions_array):2.0f}%\\n ({class_names[true_label]})\",color=color)\n","\n","for index in range(0,99): \n","    match (index%9):\n","        case (0): \n","            plt.figure(figsize=(9,9)) \n","            plt.subplot(331)\n","        case (1):\n","            plt.subplot(332)\n","        case (2):\n","            plt.subplot(333)\n","        case (3):\n","            plt.subplot(334)\n","        case (4):\n","            plt.subplot(335)\n","        case (5):\n","            plt.subplot(336)\n","        case (6):\n","            plt.subplot(337)\n","        case (7):\n","            plt.subplot(338)\n","        case (8):\n","            plt.subplot(339)\n","            plot_image(index, predictions, test_labels, test_imgs)\n","            plt.suptitle('Figure{}'.format(int(index/8)))\n","            #plt.savefig('resultImg/result{}.png'.format(int(i/8)))\n","            continue             \n","    plot_image(index, predictions, test_labels, test_imgs)\n","\n","\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"modelInstanceId":163,"sourceId":235,"sourceType":"modelInstanceVersion"},{"modelInstanceId":2482,"sourceId":3335,"sourceType":"modelInstanceVersion"},{"modelInstanceId":2613,"sourceId":3684,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
